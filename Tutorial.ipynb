{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a tutorial making use of the Contagious Naive Bayes package as described above. \n",
    "\n",
    "The objective here is to predict an individual's gender through the analysis of a tweet of their's. \n",
    "\n",
    "The dataset itself is available online at: https://www.kaggle.com/crowdflower/twitter-user-gender-classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = pd.read_csv(r\"C:\\Users\\danie\\Desktop\\University\\Internship/General/gender.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having read the data in, we inspect the dataset briefly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
      "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
      "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
      "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
      "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
      "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
      "\n",
      "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
      "0    male             1.0000        yes                    1.0   \n",
      "1    male             1.0000        yes                    1.0   \n",
      "2    male             0.6625        yes                    1.0   \n",
      "3    male             1.0000        yes                    1.0   \n",
      "4  female             1.0000        yes                    1.0   \n",
      "\n",
      "          created  ...                                       profileimage  \\\n",
      "0    12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
      "1   10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
      "2  11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
      "3   6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
      "4   4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
      "\n",
      "   retweet_count sidebar_color  \\\n",
      "0              0        FFFFFF   \n",
      "1              0        C0DEED   \n",
      "2              1        C0DEED   \n",
      "3              0        C0DEED   \n",
      "4              0             0   \n",
      "\n",
      "                                                text tweet_coord tweet_count  \\\n",
      "0  Robbie E Responds To Critics After Win Against...         NaN      110964   \n",
      "1  ÛÏIt felt like they were my friends and I was...         NaN        7471   \n",
      "2  i absolutely adore when louis starts the songs...         NaN        5617   \n",
      "3  Hi @JordanSpieth - Looking at the url - do you...         NaN        1693   \n",
      "4  Watching Neighbours on Sky+ catching up with t...         NaN       31462   \n",
      "\n",
      "    tweet_created      tweet_id   tweet_location               user_timezone  \n",
      "0  10/26/15 12:40  6.587300e+17  main; @Kan1shk3                     Chennai  \n",
      "1  10/26/15 12:40  6.587300e+17              NaN  Eastern Time (US & Canada)  \n",
      "2  10/26/15 12:40  6.587300e+17           clcncl                    Belgrade  \n",
      "3  10/26/15 12:40  6.587300e+17    Palo Alto, CA  Pacific Time (US & Canada)  \n",
      "4  10/26/15 12:40  6.587300e+17              NaN                         NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(datafile.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we are only interested within two columns within the dataset. \n",
    "\n",
    "Namely, 'text' and 'gender'. \n",
    "\n",
    "-'text' contains the content of the individual's tweet.\n",
    "\n",
    "-'gender' contains the gender of the individual. There are 3 categories that each individual can fall within, namely 'male', 'female' and 'brand'. \n",
    "\n",
    "For the purpose of this tutorial, we will ignore users who are tagged as a brand as the package was designed with binary classification in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform preprocessing to convert the observations flagged as 'male' as 0, and those flagged as female as '1' to simplify the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['text','gender']\n",
    "datafile_conv = datafile[cols]\n",
    "datafile_conv.columns = ['text','class_code']\n",
    "interm = []\n",
    "\n",
    "for i in datafile_conv['class_code']:\n",
    "  if i == 'male':\n",
    "    j = 0\n",
    "  elif i =='female':\n",
    "    j = 1\n",
    "  interm.append(j)\n",
    "\n",
    "datafile_conv['class_code'] = interm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tutorial purposes, to speed up the run time of the algorithm, rather than considering the entire dataset, we consider a subset of the data, of size 2000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_conv = datafile_conv.sample(2000,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having subsetted the data, we now perform a standard test/train split of the data in order to train the model, and then validate it. This is done so making use of sklearn readily available package, whose documentation is available at: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datafile_conv['text'], datafile_conv['class_code'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = (X_train,y_train)\n",
    "train_matrix = pd.DataFrame(train_matrix).transpose()\n",
    "train_matrix_id = train_matrix.index\n",
    "test_matrix = (X_test,y_test)\n",
    "test_matrix = pd.DataFrame(test_matrix).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having installed the package through the 'pip' command, we now utilize the package within a notebook enviroment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Contagious_NB import Classification as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package, as well as the function are now called, providing us with output. We will firstly perform the classification without making use of any normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Contagious Naive Bayes has executed.\n",
      "The total runtime was:  174.6720905303955 seconds\n",
      "The posteriors obtained are as follows: \n",
      "               0          1  Predicted  Actual\n",
      "Index                                         \n",
      "19518 -30.590401 -21.290037          1       0\n",
      "3482   -4.922357  -4.356281          1       1\n",
      "17305 -16.467453 -17.075635          0       1\n",
      "9134  -29.957109 -27.062482          1       0\n",
      "19435 -18.369295 -17.093212          1       0\n",
      "5379   -0.303753  -0.298324          1       0\n",
      "11752 -13.676371  -9.913059          1       1\n",
      "19813 -11.693105 -14.263936          0       0\n",
      "18037 -23.322129 -25.962303          0       1\n",
      "16755 -17.510576 -24.454507          0       0\n",
      "8937   -7.378762 -11.076001          0       0\n",
      "20023  -7.546340 -13.919485          0       0\n",
      "4639   -4.410793  -5.275328          0       0\n",
      "16058 -13.279373 -18.869705          0       1\n",
      "4345   -5.807669  -8.637453          0       0\n",
      "19691  -2.511892  -2.511807          1       1\n",
      "6224   -9.123099 -10.134153          0       0\n",
      "9149   -5.150102  -5.230441          0       1\n",
      "18505 -12.928762 -12.471378          1       1\n",
      "12011 -25.848646 -26.382831          0       1\n",
      "10739  -9.106404  -9.111803          0       0\n",
      "19484 -12.230048  -9.263402          1       0\n",
      "15098 -20.181970 -25.919500          0       1\n",
      "14728 -14.111450 -13.998473          1       1\n",
      "13959  -8.014511  -8.195153          0       1\n",
      "4043   -4.815663  -4.944599          0       1\n",
      "57    -24.239147 -25.850828          0       1\n",
      "9798  -25.911720 -31.599485          0       0\n",
      "8079   -9.924390  -8.958708          1       0\n",
      "3753  -11.482229  -9.085468          1       1\n",
      "...          ...        ...        ...     ...\n",
      "4528   -2.368301  -2.511807          0       0\n",
      "18940  -5.508112  -5.514598          0       0\n",
      "2300  -10.087708 -12.395707          0       1\n",
      "12058  -8.235086 -14.324480          0       1\n",
      "2457  -14.342057 -13.834671          1       0\n",
      "18866  -8.733653  -7.322351          1       0\n",
      "6619   -8.654948 -12.301505          0       1\n",
      "3488   -3.937435  -4.479943          0       1\n",
      "17807 -28.724638 -16.181931          1       0\n",
      "4999   -5.150102  -5.230441          0       0\n",
      "11058 -25.216416 -29.456794          0       0\n",
      "6714  -17.536304 -24.960799          0       0\n",
      "6717   -5.150102  -5.230441          0       0\n",
      "7363  -17.536304 -24.960799          0       0\n",
      "3077   -6.107226  -9.111803          0       1\n",
      "3570   -8.534643 -11.544596          0       0\n",
      "1968  -26.621945 -19.591126          1       1\n",
      "20010  -7.251751 -10.415000          0       1\n",
      "17728  -3.780437  -4.104804          0       1\n",
      "6179  -13.724528 -13.232825          1       0\n",
      "15594 -18.526180 -13.493279          1       0\n",
      "3394  -11.747458 -14.896734          0       1\n",
      "3725  -17.872546 -16.749066          1       1\n",
      "9152  -12.008140 -12.018946          0       0\n",
      "4548   -8.709406 -11.544596          0       0\n",
      "9693  -16.974425 -16.636075          1       0\n",
      "7417  -10.700759 -16.446892          0       1\n",
      "6301   -5.150102  -5.230441          0       0\n",
      "8590   -5.335718  -4.647364          1       0\n",
      "19817 -18.918305 -18.896426          1       1\n",
      "\n",
      "[400 rows x 4 columns]\n",
      "The performance metrics obtained are as follows:                    0\n",
      "Accuracy   0.517500\n",
      "Precision  0.505435\n",
      "Recall     0.476923\n",
      "F1         0.490765\n"
     ]
    }
   ],
   "source": [
    "cnb = func.CNB(train_matrix,test_matrix, norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done the above, we now repeat the process making use of document length normalization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Contagious Naive Bayes has executed.\n",
      "The total runtime was:  41.43412184715271 seconds\n",
      "The posteriors obtained are as follows: \n",
      "               0          1  Predicted  Actual\n",
      "Index                                         \n",
      "19518 -25.249704 -15.647730          1       0\n",
      "3482   -3.293720  -2.689334          1       1\n",
      "17305  -9.787161 -10.324267          0       1\n",
      "9134  -16.499229 -19.649555          0       0\n",
      "19435 -14.066342 -12.535494          1       0\n",
      "5379   -0.303196  -0.298875          1       0\n",
      "11752 -12.262596 -11.247985          1       1\n",
      "19813  -7.402014 -10.060195          0       0\n",
      "18037 -18.475814 -24.220325          0       1\n",
      "16755 -11.441411 -18.325111          0       0\n",
      "8937   -4.635231  -7.867263          0       0\n",
      "20023  -4.892830 -11.295643          0       0\n",
      "4639   -2.764030  -3.548932          0       0\n",
      "16058 -10.335930 -15.238321          0       1\n",
      "4345   -4.039880  -6.868240          0       0\n",
      "19691  -1.531674  -1.657447          0       1\n",
      "6224   -5.602019  -6.663684          0       0\n",
      "9149   -4.658177  -4.597639          1       1\n",
      "18505 -10.164041  -7.397607          1       1\n",
      "12011 -19.635990 -19.900030          0       1\n",
      "10739  -7.321326  -7.325464          0       0\n",
      "19484 -12.059925  -6.113332          1       0\n",
      "15098 -14.014351 -19.839803          0       1\n",
      "14728  -8.248008  -5.116708          1       1\n",
      "13959  -6.416571  -9.974904          0       1\n",
      "4043   -3.099742  -3.218203          0       1\n",
      "57    -18.676008 -21.000494          0       1\n",
      "9798  -19.202424 -22.022183          0       0\n",
      "8079   -5.910533  -5.036807          1       0\n",
      "3753   -8.259694  -5.516814          1       1\n",
      "...          ...        ...        ...     ...\n",
      "4528   -3.545472  -3.762512          0       0\n",
      "18940  -3.748968  -3.762512          0       0\n",
      "2300   -6.487913  -8.934816          0       1\n",
      "12058  -5.596649 -11.674667          0       1\n",
      "2457   -9.204054  -8.527731          1       0\n",
      "18866  -5.448382  -4.071290          1       0\n",
      "6619   -7.254743 -11.136605          0       1\n",
      "3488   -4.431555  -7.847789          0       1\n",
      "17807 -22.103732  -9.962421          1       0\n",
      "4999   -4.658177  -4.316325          1       0\n",
      "11058 -17.247986 -21.154117          0       0\n",
      "6714  -12.493393 -19.595818          0       0\n",
      "6717   -4.492059  -4.229241          1       0\n",
      "7363  -12.493393 -19.595818          0       0\n",
      "3077   -4.330792  -7.325464          0       1\n",
      "3570   -7.786357 -13.894830          0       0\n",
      "1968  -15.622341 -11.672970          1       1\n",
      "20010  -6.185447  -6.840392          0       1\n",
      "17728  -2.344211  -2.660994          0       1\n",
      "6179   -7.744181  -7.105702          1       0\n",
      "15594 -13.336309  -8.492817          1       0\n",
      "3394   -7.223212 -10.751183          0       1\n",
      "3725   -9.864089 -11.690496          0       1\n",
      "9152   -7.321326  -4.043825          1       0\n",
      "4548   -6.053679 -11.876850          0       0\n",
      "9693  -12.529317 -11.716723          1       0\n",
      "7417   -7.206316 -13.147687          0       1\n",
      "6301   -4.163769  -4.102745          1       0\n",
      "8590   -3.602508  -2.946657          1       0\n",
      "19817 -22.225529 -21.567005          1       1\n",
      "\n",
      "[400 rows x 4 columns]\n",
      "The performance metrics obtained are as follows:                    0\n",
      "Accuracy   0.497500\n",
      "Precision  0.485437\n",
      "Recall     0.512821\n",
      "F1         0.498753\n"
     ]
    }
   ],
   "source": [
    "cnb_norm = func.CNB(train_matrix,test_matrix, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows us that the choice between whether or not to make use of document length normalization in this case is a subjective one. Which can be fine tuned through the use of the additional arguments available. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
